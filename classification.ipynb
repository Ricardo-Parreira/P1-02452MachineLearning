{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebcf5a80-28b4-4b95-b901-59932e86acc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T17:38:10.585889Z",
     "start_time": "2025-10-28T17:37:59.473781Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV fold: 100%|██████████| 10/10 [00:20<00:00,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table 2 (classification; two-level CV) \n",
      " fold  lambda* (log)  Etest_log  k* (knn)  Etest_knn  Etest_base\n",
      "    1       100.0000     0.2979        15     0.3617      0.3404\n",
      "    2         1.0000     0.3617        15     0.3617      0.3404\n",
      "    3         0.0001     0.3913        15     0.3261      0.3478\n",
      "    4       100.0000     0.3043        15     0.3261      0.3478\n",
      "    5        10.0000     0.1957        11     0.3043      0.3478\n",
      "    6         1.0000     0.2609        13     0.3261      0.3478\n",
      "    7        10.0000     0.2174        13     0.2174      0.3478\n",
      "    8        10.0000     0.2826        15     0.3043      0.3478\n",
      "    9        10.0000     0.3261        13     0.3261      0.3478\n",
      "   10         0.0001     0.1957        11     0.2391      0.3478\n",
      "\n",
      "Summary\n",
      "  method  Etest_mean  Etest_sd\n",
      "logistic      0.2833    0.0671\n",
      "     knn      0.3093    0.0472\n",
      "baseline      0.3463    0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "from collections import Counter\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed); random.seed(seed)\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "if \"famhist\" in df.columns:\n",
    "    df[\"famhist\"] = df[\"famhist\"].map({\"Absent\":0,\"Present\":1}).astype(int)\n",
    "\n",
    "for col in [\"tobacco\",\"alcohol\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = np.log1p(df[col])\n",
    "\n",
    "y = df[\"chd\"].astype(int)\n",
    "X = df.drop(columns=[\"chd\"])\n",
    "\n",
    "def error_rate(y_true, y_pred):\n",
    "    return np.mean(y_true != y_pred)\n",
    "\n",
    "logistic = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "knn = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "lambda_range = [1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "C_range = [1.0/l for l in lambda_range]\n",
    "k_range = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "K=10\n",
    "outer = StratifiedKFold(K, shuffle=True, random_state=seed)\n",
    "outer_splits = list(outer.split(X, y))\n",
    "\n",
    "rows = []\n",
    "y_true_all, yhat_log_all, yhat_knn_all, yhat_base_all = [], [], [], []\n",
    "\n",
    "for fold_idx, (train_index, test_index) in tqdm(\n",
    "    enumerate(outer_splits, start=1),\n",
    "    total=len(outer_splits),\n",
    "    desc=\"Outer CV fold\"\n",
    "):\n",
    "    # Outer split\n",
    "    X_train, y_train = X.iloc[train_index,:], y.iloc[train_index]\n",
    "    X_test,  y_test  = X.iloc[test_index,:],  y.iloc[test_index]\n",
    "\n",
    "    # Baseline\n",
    "    maj = Counter(y_train).most_common(1)[0][0]\n",
    "    yhat_base = np.full_like(y_test, fill_value=maj)\n",
    "\n",
    "    # Inner CV Log. Regression\n",
    "    inner = StratifiedKFold(K, shuffle=True, random_state=123)\n",
    "    best_C, best_score = None, -np.inf\n",
    "\n",
    "    for C in C_range:\n",
    "        fold_scores = []\n",
    "        for tr_in, va_in in inner.split(X_train, y_train):\n",
    "            Xi_tr, yi_tr = X_train.iloc[tr_in,:], y_train.iloc[tr_in]\n",
    "            Xi_va, yi_va = X_train.iloc[va_in,:], y_train.iloc[va_in]\n",
    "\n",
    "            model = clone(logistic)\n",
    "            model.set_params(clf__C=C)\n",
    "            model.fit(Xi_tr, yi_tr)\n",
    "            y_pred_va = model.predict(Xi_va)\n",
    "            fold_scores.append(accuracy_score(yi_va, y_pred_va))\n",
    "        mean_acc = np.mean(fold_scores)\n",
    "        if mean_acc > best_score:\n",
    "            best_score = mean_acc\n",
    "            best_C = C\n",
    "\n",
    "    final_log = clone(logistic).set_params(clf__C=best_C).fit(X_train, y_train)\n",
    "    yhat_log = final_log.predict(X_test)\n",
    "    Etest_log = error_rate(y_test, yhat_log)\n",
    "    lambda_star = 1.0 / best_C\n",
    "\n",
    "    # Inner CV KNN\n",
    "    best_k, best_score = None, -np.inf\n",
    "\n",
    "    for k in k_range:\n",
    "        fold_scores = []\n",
    "        for tr_in, va_in in inner.split(X_train, y_train):\n",
    "            Xi_tr, yi_tr = X_train.iloc[tr_in,:], y_train.iloc[tr_in]\n",
    "            Xi_va, yi_va = X_train.iloc[va_in,:], y_train.iloc[va_in]\n",
    "\n",
    "            model = clone(knn)\n",
    "            model.set_params(clf__n_neighbors=k)\n",
    "            model.fit(Xi_tr, yi_tr)\n",
    "            y_pred_va = model.predict(Xi_va)\n",
    "            fold_scores.append(accuracy_score(yi_va, y_pred_va))\n",
    "        mean_acc = np.mean(fold_scores)\n",
    "        if mean_acc > best_score:\n",
    "            best_score = mean_acc\n",
    "            best_k = k\n",
    "\n",
    "    final_knn = clone(knn).set_params(clf__n_neighbors=best_k).fit(X_train, y_train)\n",
    "    yhat_knn = final_knn.predict(X_test)\n",
    "    Etest_knn = error_rate(y_test, yhat_knn)\n",
    "\n",
    "    Etest_base = error_rate(y_test, yhat_base)\n",
    "\n",
    "    rows.append({\n",
    "        \"fold\": fold_idx,\n",
    "        \"lambda* (log)\": lambda_star,\n",
    "        \"Etest_log\": Etest_log,\n",
    "        \"k* (knn)\": best_k,\n",
    "        \"Etest_knn\": Etest_knn,\n",
    "        \"Etest_base\": Etest_base\n",
    "    })\n",
    "\n",
    "    y_true_all.append(y_test.values)\n",
    "    yhat_log_all.append(yhat_log)\n",
    "    yhat_knn_all.append(yhat_knn)\n",
    "    yhat_base_all.append(yhat_base)\n",
    "\n",
    "table_cls = pd.DataFrame(rows)\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"method\": [\"logistic\", \"knn\", \"baseline\"],\n",
    "    \"Etest_mean\": [\n",
    "        table_cls[\"Etest_log\"].mean(),\n",
    "        table_cls[\"Etest_knn\"].mean(),\n",
    "        table_cls[\"Etest_base\"].mean()\n",
    "    ],\n",
    "    \"Etest_sd\": [\n",
    "        table_cls[\"Etest_log\"].std(ddof=1),\n",
    "        table_cls[\"Etest_knn\"].std(ddof=1),\n",
    "        table_cls[\"Etest_base\"].std(ddof=1)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nTable 2 (classification; two-level CV) \")\n",
    "print(table_cls.round(4).to_string(index=False))\n",
    "\n",
    "print(\"\\nSummary\")\n",
    "print(summary.round(4).to_string(index=False))\n",
    "\n",
    "y_true_all  = np.concatenate(y_true_all)\n",
    "yhat_log_all  = np.concatenate(yhat_log_all)\n",
    "yhat_knn_all  = np.concatenate(yhat_knn_all)\n",
    "yhat_base_all = np.concatenate(yhat_base_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e675d09f4dd855a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T09:55:21.189674Z",
     "start_time": "2025-10-28T09:55:15.747626Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV fold: 100%|██████████| 10/10 [00:05<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table 2 (classification; two-level CV) \n",
      " fold  lambda* (log)  Etest_log  k* (knn)  Etest_knn  Etest_base\n",
      "    1       100.0000     0.2979        15     0.3617      0.3404\n",
      "    2         1.0000     0.3617        15     0.3617      0.3404\n",
      "    3         0.0001     0.3913        15     0.3261      0.3478\n",
      "    4       100.0000     0.3043        15     0.3261      0.3478\n",
      "    5        10.0000     0.1957        11     0.3043      0.3478\n",
      "    6         1.0000     0.2609        13     0.3261      0.3478\n",
      "    7        10.0000     0.2174        13     0.2174      0.3478\n",
      "    8        10.0000     0.2826        15     0.3043      0.3478\n",
      "    9        10.0000     0.3261        13     0.3261      0.3478\n",
      "   10         0.0001     0.1957        11     0.2391      0.3478\n",
      "\n",
      "Summary\n",
      "  method  Etest_mean  Etest_sd\n",
      "logistic      0.2833    0.0671\n",
      "     knn      0.3093    0.0472\n",
      "baseline      0.3463    0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler   # (import mantido, não usado)\n",
    "from sklearn.pipeline import Pipeline              # (import mantido, não usado)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "from collections import Counter\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed); random.seed(seed)\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "if \"famhist\" in df.columns:\n",
    "    df[\"famhist\"] = df[\"famhist\"].map({\"Absent\":0,\"Present\":1}).astype(int)\n",
    "for col in [\"tobacco\",\"alcohol\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = np.log1p(df[col])\n",
    "\n",
    "y = df[\"chd\"].astype(int)\n",
    "X = df.drop(columns=[\"chd\"])\n",
    "\n",
    "# ==== trocado: sem Pipeline/StandardScaler; modelos \"puros\"\n",
    "logistic = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", max_iter=1000)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "lambda_range = [1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "C_range = [1.0/l for l in lambda_range]\n",
    "k_range = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "outer = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "outer_splits = list(outer.split(X, y))\n",
    "\n",
    "rows = []\n",
    "y_true_all, yhat_log_all, yhat_knn_all, yhat_base_all = [], [], [], []\n",
    "\n",
    "# helper: normalização manual com stats do treino\n",
    "def standardize_train_test(X_tr, X_te):\n",
    "    # aceita DataFrame ou ndarray\n",
    "    Xtr = X_tr.to_numpy() if hasattr(X_tr, \"to_numpy\") else np.asarray(X_tr)\n",
    "    Xte = X_te.to_numpy() if hasattr(X_te, \"to_numpy\") else np.asarray(X_te)\n",
    "    mu = np.mean(Xtr, axis=0)\n",
    "    sd = np.std(Xtr, axis=0, ddof=0)\n",
    "    sd_safe = sd.copy()\n",
    "    sd_safe[sd_safe == 0] = 1.0\n",
    "    return (Xtr - mu)/sd_safe, (Xte - mu)/sd_safe\n",
    "\n",
    "for fold_idx, (train_index, test_index) in tqdm(\n",
    "    enumerate(outer_splits, start=1),\n",
    "    total=len(outer_splits),\n",
    "    desc=\"Outer CV fold\"\n",
    "):\n",
    "    # Outer split\n",
    "    X_train, y_train = X.iloc[train_index,:], y.iloc[train_index]\n",
    "    X_test,  y_test  = X.iloc[test_index,:],  y.iloc[test_index]\n",
    "\n",
    "    # Baseline\n",
    "    maj = Counter(y_train).most_common(1)[0][0]\n",
    "    yhat_base = np.full_like(y_test, fill_value=maj)\n",
    "    Etest_base = 1 - accuracy_score(y_test, yhat_base)\n",
    "\n",
    "    # ===== Inner CV Log. Regression (seleção de C) =====\n",
    "    inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=123)\n",
    "    best_C, best_score = None, -np.inf\n",
    "\n",
    "    for C in C_range:\n",
    "        fold_scores = []\n",
    "        for tr_in, va_in in inner.split(X_train, y_train):\n",
    "            Xi_tr, yi_tr = X_train.iloc[tr_in,:], y_train.iloc[tr_in]\n",
    "            Xi_va, yi_va = X_train.iloc[va_in,:], y_train.iloc[va_in]\n",
    "\n",
    "            # normalize dentro do inner fold\n",
    "            Xi_tr_s, Xi_va_s = standardize_train_test(Xi_tr, Xi_va)\n",
    "\n",
    "            model = clone(logistic)\n",
    "            model.set_params(C=C)\n",
    "            model.fit(Xi_tr_s, yi_tr)\n",
    "            y_pred_va = model.predict(Xi_va_s)\n",
    "            fold_scores.append(accuracy_score(yi_va, y_pred_va))\n",
    "        mean_acc = np.mean(fold_scores)\n",
    "        if mean_acc > best_score:\n",
    "            best_score = mean_acc\n",
    "            best_C = C\n",
    "\n",
    "    # Refit final LR no outer (normalização com stats do outer-train)\n",
    "    Xtr_s_outer, Xte_s_outer = standardize_train_test(X_train, X_test)\n",
    "    final_log = clone(logistic).set_params(C=best_C).fit(Xtr_s_outer, y_train)\n",
    "    yhat_log = final_log.predict(Xte_s_outer)\n",
    "    Etest_log = error_rate(y_test, yhat_log)\n",
    "    lambda_star = 1.0 / best_C\n",
    "\n",
    "    # ===== Inner CV KNN =====\n",
    "    best_k, best_score = None, -np.inf\n",
    "\n",
    "    for k in k_range:\n",
    "        fold_scores = []\n",
    "        for tr_in, va_in in inner.split(X_train, y_train):\n",
    "            Xi_tr, yi_tr = X_train.iloc[tr_in,:], y_train.iloc[tr_in]\n",
    "            Xi_va, yi_va = X_train.iloc[va_in,:], y_train.iloc[va_in]\n",
    "\n",
    "            Xi_tr_s, Xi_va_s = standardize_train_test(Xi_tr, Xi_va)\n",
    "\n",
    "            model = clone(knn)\n",
    "            model.set_params(n_neighbors=k)\n",
    "            model.fit(Xi_tr_s, yi_tr)\n",
    "            y_pred_va = model.predict(Xi_va_s)\n",
    "            fold_scores.append(accuracy_score(yi_va, y_pred_va))\n",
    "        mean_acc = np.mean(fold_scores)\n",
    "        if mean_acc > best_score:\n",
    "            best_score = mean_acc\n",
    "            best_k = k\n",
    "\n",
    "    # Refit final KNN no outer (com a mesma normalização do outer)\n",
    "    final_knn = clone(knn).set_params(n_neighbors=best_k).fit(Xtr_s_outer, y_train)\n",
    "    yhat_knn = final_knn.predict(Xte_s_outer)\n",
    "    Etest_knn = 1 - accuracy_score(y_test, yhat_knn)\n",
    "\n",
    "#----------------------------------------------\n",
    "\n",
    "    rows.append({\n",
    "        \"fold\": fold_idx,\n",
    "        \"lambda* (log)\": lambda_star,\n",
    "        \"Etest_log\": Etest_log,\n",
    "        \"k* (knn)\": best_k,\n",
    "        \"Etest_knn\": Etest_knn,\n",
    "        \"Etest_base\": Etest_base\n",
    "    })\n",
    "\n",
    "    y_true_all.append(y_test.values)\n",
    "    yhat_log_all.append(yhat_log)\n",
    "    yhat_knn_all.append(yhat_knn)\n",
    "    yhat_base_all.append(yhat_base)\n",
    "\n",
    "\n",
    "table_cls = pd.DataFrame(rows)\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"method\": [\"logistic\", \"knn\", \"baseline\"],\n",
    "    \"Etest_mean\": [\n",
    "        table_cls[\"Etest_log\"].mean(),\n",
    "        table_cls[\"Etest_knn\"].mean(),\n",
    "        table_cls[\"Etest_base\"].mean()\n",
    "    ],\n",
    "    \"Etest_sd\": [\n",
    "        table_cls[\"Etest_log\"].std(ddof=1),\n",
    "        table_cls[\"Etest_knn\"].std(ddof=1),\n",
    "        table_cls[\"Etest_base\"].std(ddof=1)\n",
    "    ]\n",
    "})\n",
    "#----------------------------------------------\n",
    "\n",
    "print(\"\\nTable 2 (classification; two-level CV) \")\n",
    "print(table_cls.round(4).to_string(index=False))\n",
    "\n",
    "print(\"\\nSummary\")\n",
    "print(summary.round(4).to_string(index=False))\n",
    "\n",
    "y_true_all  = np.concatenate(y_true_all)\n",
    "yhat_log_all  = np.concatenate(yhat_log_all)\n",
    "yhat_knn_all  = np.concatenate(yhat_knn_all)\n",
    "yhat_base_all = np.concatenate(yhat_base_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f131595934310cbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T09:55:21.280264Z",
     "start_time": "2025-10-28T09:55:21.278618Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce1910eb5480b107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T19:12:07.664269Z",
     "start_time": "2025-10-28T19:12:05.159343Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table 2\n",
      " fold  lambda* (log)  Etest_log  k* (knn)  Etest_knn  Etest_base\n",
      "    0       100.0000     0.2979        15     0.3617      0.3404\n",
      "    1         1.0000     0.3617        15     0.3617      0.3404\n",
      "    2         0.0001     0.3913        15     0.3261      0.3478\n",
      "    3       100.0000     0.3043        15     0.3261      0.3478\n",
      "    4        10.0000     0.1957        11     0.3043      0.3478\n",
      "    5         1.0000     0.2609        13     0.3261      0.3478\n",
      "    6        10.0000     0.2174        13     0.2174      0.3478\n",
      "    7        10.0000     0.2826        15     0.3043      0.3478\n",
      "    8        10.0000     0.3261        13     0.3261      0.3478\n",
      "    9         0.0001     0.1957        11     0.2391      0.3478\n",
      "\n",
      "Summary \n",
      "  method  Etest_mean  Etest_sd\n",
      "logistic      0.2833    0.0671\n",
      "     knn      0.3093    0.0472\n",
      "baseline      0.3463    0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#COM PIPELINE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    "# ----------------------------\n",
    "# Setup\n",
    "# ----------------------------\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# ----------------------------\n",
    "# Load and preprocess data\n",
    "# ----------------------------\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Map famhist to numeric\n",
    "if \"famhist\" in df.columns:\n",
    "    df[\"famhist\"] = df[\"famhist\"].map({\"Absent\": 0, \"Present\": 1}).astype(int)\n",
    "\n",
    "# Fix skewed variables\n",
    "for col in [\"tobacco\", \"alcohol\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = np.log1p(df[col])\n",
    "\n",
    "# Define features and target\n",
    "y = df[\"chd\"].astype(int)\n",
    "X = df.drop(columns=[\"chd\"])\n",
    "\n",
    "# ----------------------------\n",
    "# Pipelines (scaling inside CV)\n",
    "# ----------------------------\n",
    "logistic = Pipeline([(\"scaler\", StandardScaler()),(\"clf\", LogisticRegression(max_iter=1000))])\n",
    "\n",
    "knn = Pipeline([(\"scaler\", StandardScaler()),(\"clf\", KNeighborsClassifier())])\n",
    "\n",
    "# ----------------------------\n",
    "# Parameter grids\n",
    "# ----------------------------\n",
    "lambda_range = [1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "C_range = [1.0 / lam for lam in lambda_range]  # sklearn uses C = 1/λ\n",
    "k_range = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "param_grid_log = {\"clf__C\": C_range}\n",
    "param_grid_knn = {\"clf__n_neighbors\": k_range}\n",
    "\n",
    "# ----------------------------\n",
    "# Two-level CV (outer + inner)\n",
    "# ----------------------------\n",
    "outer = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "#outer_splits = list(outer.split(X, y))\n",
    "\n",
    "rows = []\n",
    "y_true_all = []\n",
    "yhat_log_all = []\n",
    "yhat_knn_all = []\n",
    "yhat_base_all = []\n",
    "\n",
    "for fold_idx, (train_index, test_index) in tqdm(enumerate(outer.split(X,y)),total=outer.get_n_splits(X,y),desc=\"Cross-validation fold\"\n",
    "):\n",
    "\n",
    "    X_train = X.iloc[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X.iloc[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    # --- Baseline ---\n",
    "    maj = Counter(y_train).most_common(1)[0][0]\n",
    "    ypredict_base = np.array([maj] * len(y_test))\n",
    "    Etest_base = sum(y_test != ypredict_base) / len(ypredict_base)\n",
    "\n",
    "    # --- Logistic Regression (inner CV) ---\n",
    "    inner = StratifiedKFold(n_splits=10, shuffle=True,random_state=123)\n",
    "\n",
    "    g_log = GridSearchCV(\n",
    "        estimator=logistic,\n",
    "        param_grid=param_grid_log,\n",
    "        cv=inner,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    g_log.fit(X_train, y_train)\n",
    "    ypredict_log = g_log.predict(X_test)\n",
    "    Etest_log = sum(y_test != ypredict_log) / len(ypredict_log)\n",
    "    lambda_star = 1.0 / g_log.best_params_[\"clf__C\"]\n",
    "\n",
    "    # --- KNN (inner CV) ---\n",
    "    g_knn = GridSearchCV(\n",
    "        estimator=knn,\n",
    "        param_grid=param_grid_knn,\n",
    "        cv=inner,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    g_knn.fit(X_train, y_train)\n",
    "    ypredict_knn = g_knn.predict(X_test)\n",
    "    Etest_knn = sum(y_test != ypredict_knn) / len(ypredict_knn)\n",
    "    k_star = g_knn.best_params_[\"clf__n_neighbors\"]\n",
    "\n",
    "    # --- Save results ---\n",
    "    rows.append({\n",
    "        \"fold\": fold_idx,\n",
    "        \"lambda* (log)\": lambda_star,\n",
    "        \"Etest_log\": Etest_log,\n",
    "        \"k* (knn)\": k_star,\n",
    "        \"Etest_knn\": Etest_knn,\n",
    "        \"Etest_base\": Etest_base\n",
    "    })\n",
    "\n",
    "    # Save predictions for future tests (McNemar, etc.)\n",
    "    y_true_all.append(y_test.values)\n",
    "    yhat_log_all.append(yhat_log)\n",
    "    yhat_knn_all.append(yhat_knn)\n",
    "    yhat_base_all.append(yhat_base)\n",
    "\n",
    "# ----------------------------\n",
    "# Results summary\n",
    "# ----------------------------\n",
    "table = pd.DataFrame(rows)\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"method\": [\"logistic\", \"knn\", \"baseline\"],\n",
    "    \"Etest_mean\": [\n",
    "        table[\"Etest_log\"].mean(),\n",
    "        table[\"Etest_knn\"].mean(),\n",
    "        table[\"Etest_base\"].mean()\n",
    "    ],\n",
    "    \"Etest_sd\": [\n",
    "        table[\"Etest_log\"].std(ddof=1),\n",
    "        table[\"Etest_knn\"].std(ddof=1),\n",
    "        table[\"Etest_base\"].std(ddof=1)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nTable 2\")\n",
    "print(table.round(4).to_string(index=False))\n",
    "\n",
    "print(\"\\nSummary \")\n",
    "print(summary.round(4).to_string(index=False))\n",
    "\n",
    "# Prepare concatenated arrays for next section\n",
    "y_true_all = np.concatenate(y_true_all)\n",
    "yhat_log_all = np.concatenate(yhat_log_all)\n",
    "yhat_knn_all = np.concatenate(yhat_knn_all)\n",
    "yhat_base_all = np.concatenate(yhat_base_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f88841106e044dac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T22:11:14.316889Z",
     "start_time": "2025-10-28T22:11:12.438971Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table per fold\n",
      "   fold  lambda* (log)  Etest_log  k* (knn)  Etest_knn  Etest_base\n",
      "0     0       100.0000     0.2979        11     0.3404      0.3404\n",
      "1     1         1.0000     0.3617        15     0.3617      0.3404\n",
      "2     2         0.0001     0.3913        11     0.3696      0.3478\n",
      "3     3       100.0000     0.3043        15     0.3261      0.3478\n",
      "4     4        10.0000     0.1957        15     0.2391      0.3478\n",
      "5     5        10.0000     0.2609        13     0.3261      0.3478\n",
      "6     6        10.0000     0.2174        15     0.2609      0.3478\n",
      "7     7        10.0000     0.2826        11     0.2826      0.3478\n",
      "8     8        10.0000     0.3261        15     0.3043      0.3478\n",
      "9     9         0.0001     0.1957        13     0.2391      0.3478\n",
      "\n",
      "Summary\n",
      "     method  Etest_mean  Etest_sd\n",
      "0  logistic      0.2833    0.0671\n",
      "1       knn      0.3050    0.0479\n",
      "2  baseline      0.3463    0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#SEM PIPELINE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "SEED_2 = 123\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "#absent/present to 0/1\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "if \"famhist\" in df.columns:\n",
    "    df[\"famhist\"] = df[\"famhist\"].map({\"Absent\": 0, \"Present\": 1}).astype(int)\n",
    "\n",
    "#skewed attributes\n",
    "for col in [\"tobacco\", \"alcohol\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = np.log1p(df[col])\n",
    "\n",
    "y = df[\"chd\"].astype(int)\n",
    "X = df.drop(columns=[\"chd\"])\n",
    "\n",
    "#parameters to test\n",
    "lambda_range = [1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "C_range = [1.0 / lam for lam in lambda_range]\n",
    "k_range = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "#for gridsearch\n",
    "param_grid_log = {\"C\": C_range}\n",
    "param_grid_knn = {\"n_neighbors\": k_range}\n",
    "\n",
    "# two-level cross-validation\n",
    "outer = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "rows = []\n",
    "y_true_all = []\n",
    "ypredict_log_all = []\n",
    "ypredict_knn_all = []\n",
    "ypredict_base_all = []\n",
    "\n",
    "#outer\n",
    "for fold_idx, (train_index, test_index) in tqdm(\n",
    "    enumerate(outer.split(X, y)),\n",
    "    total=outer.get_n_splits(X, y),\n",
    "    desc=\"Cross-validation fold\"\n",
    "):\n",
    "\n",
    "    X_train = X.iloc[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X.iloc[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    #normalize data\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # baseline\n",
    "    maj = Counter(y_train).most_common(1)[0][0]\n",
    "    ypredict_base = np.array([maj] * len(y_test))\n",
    "    Etest_base = sum(y_test != ypredict_base) / len(ypredict_base)\n",
    "\n",
    "    # inner logistic regression\n",
    "    inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED_2)\n",
    "\n",
    "    grid_log = GridSearchCV(\n",
    "        estimator=LogisticRegression(max_iter=1000),\n",
    "        param_grid=param_grid_log,\n",
    "        cv=inner,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_log.fit(X_train_scaled, y_train)\n",
    "    ypredict_log = grid_log.predict(X_test_scaled)\n",
    "    Etest_log = sum(y_test != ypredict_log) / len(ypredict_log)\n",
    "    lambda_star = 1.0 / grid_log.best_params_[\"C\"]\n",
    "\n",
    "    # inner knn\n",
    "    grid_knn = GridSearchCV(\n",
    "        estimator=KNeighborsClassifier(),\n",
    "        param_grid=param_grid_knn,\n",
    "        cv=inner,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_knn.fit(X_train_scaled, y_train)\n",
    "    ypredict_knn = grid_knn.predict(X_test_scaled)\n",
    "    Etest_knn = sum(y_test != ypredict_knn) / len(ypredict_knn)\n",
    "    k_star = grid_knn.best_params_[\"n_neighbors\"]\n",
    "\n",
    "\n",
    "    rows.append({\"fold\": fold_idx,\n",
    "        \"lambda* (log)\": lambda_star,\n",
    "        \"Etest_log\": Etest_log,\n",
    "        \"k* (knn)\": k_star,\n",
    "        \"Etest_knn\": Etest_knn,\n",
    "        \"Etest_base\": Etest_base\n",
    "    })\n",
    "\n",
    "    #for next step\n",
    "    y_true_all.append(y_test.values)\n",
    "    ypredict_log_all.append(ypredict_log)\n",
    "    ypredict_knn_all.append(ypredict_knn)\n",
    "    ypredict_base_all.append(ypredict_base)\n",
    "\n",
    "#results\n",
    "overview = []\n",
    "for nome, coluna in [(\"logistic\", \"Etest_log\"), (\"knn\", \"Etest_knn\"), (\"baseline\", \"Etest_base\")]:\n",
    "    vals = table[coluna].values\n",
    "    overview.append({\"method\": nome, \"Etest_mean\": float(np.mean(vals)), \"Etest_sd\": float(np.std(vals, ddof=1))})\n",
    "\n",
    "summary = pd.DataFrame(overview)\n",
    "\n",
    "print(\"\\nTable per fold\")\n",
    "print(table.round(4))\n",
    "\n",
    "print(\"\\nSummary\")\n",
    "print(summary.round(4))\n",
    "\n",
    "#for next step\n",
    "y_true_all = np.concatenate(y_true_all)\n",
    "ypredict_log_all = np.concatenate(ypredict_log_all)\n",
    "ypredict_knn_all = np.concatenate(ypredict_knn_all)\n",
    "ypredict_base_all = np.concatenate(ypredict_base_all)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1a16aa",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c4dace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularize_data(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df['famhist'] = df['famhist'].map({'Present': 1, 'Absent': 0})\n",
    "    df = (df-df.mean()) / df.std()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "468668c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias: [-0.87863012]\n",
      "Features: ['sbp', 'tobacco', 'ldl', 'adiposity', 'famhist', 'typea', 'obesity', 'alcohol', 'age']\n",
      "Coefficients for each feature: [[ 0.13321451  0.36438477  0.36031357  0.14263364  0.45636594  0.38864065\n",
      "  -0.26353865  0.00313647  0.66182163]]\n",
      "Logistic Regression Accuracy: 0.7338\n",
      "Logistic Regression MSE: 0.2662\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def logistic_regression_classification():\n",
    "    threshold = 0.5\n",
    "\n",
    "    df = regularize_data(\"data.csv\")\n",
    "    y = (df[\"chd\"]>threshold).astype(int)\n",
    "    X = df.drop(columns=[\"chd\", \"row.names\"])\n",
    "\n",
    "\n",
    "    lambda_val = 0.1 #pode ter que ser mudado porque depende do ponto 4\n",
    "\n",
    "\n",
    "    C_val = 1 / lambda_val\n",
    "    logreg_model = LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        C=100,\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    logreg_model.fit(X, y)\n",
    "\n",
    "    print(\"Bias:\", logreg_model.intercept_)\n",
    "    print(\"Features:\", X.columns.tolist())\n",
    "    print(\"Coefficients for each feature:\", logreg_model.coef_)\n",
    "\n",
    "\n",
    "    y_pred = logreg_model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    # mse\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "\n",
    "    print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Logistic Regression MSE: {mse:.4f}\")\n",
    "\n",
    "logistic_regression_classification()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
